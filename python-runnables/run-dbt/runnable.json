/* This file is the descriptor for the python runnable run-dbt */
{
    "meta": {
        // label: name of the runnable as displayed, should be short
        "label": "Run dbt project from your git repo",

        // description: longer string to help end users understand what this runnable does
        "description": "This Macro allows you to run dbt project from a git repo",

        // icon: must be one of the FontAwesome 5.15.4 icons, complete list here at https://fontawesome.com/v5/docs/
        "icon": "fas fa-database"
    },

    /* whether the runnable's code is untrusted */
    "impersonate": true,
    "paramsPythonSetup": "params_helper.py",
    /* params:
    DSS will generate a formular from this list of requested parameters.
    Your component code can then access the value provided by users using the "name" field of each parameter.

    Available parameter types include:
    STRING, INT, DOUBLE, BOOLEAN, DATE, SELECT, TEXTAREA, DATASET, DATASET_COLUMN, MANAGED_FOLDER, PRESET and others.

    For the full list and for more details, see the documentation: https://doc.dataiku.com/dss/latest/plugins/reference/params.html
    */
    "params": [
        {
            "name": "git_repo_url",
            "label": "Git repo url",
            "type": "STRING",
            "description": "The git repo to fetach the dbt project from",
            "mandatory": true,
            "defaultValue": "https://github.com/johnson-zhang-au/dbt-cloud-snowflake-demo.git"
        },
        {
            "name": "branch_name",
            "label": "Git branch name",
            "type": "STRING",
            "description": "The git repo branch name to fetach the dbt project from",
            "defaultValue": "main",
            "mandatory": true
            /* Note that standard json parsing will return it as a double in Python (instead of an int), so you need to write
               int(self.config()['parameter2'])
            */
        },

        /* A "SELECT" parameter is a multi-choice selector. Choices are specified using the selectChoice field*/
        {
            "name": "connection_name",
            "label": "Database connection name",
            "type": "SELECT",
            "description": "Connection name to the database (Currently Snowflake only)",
            "getChoicesFromPython": true
        },
        {
            "name": "sf_user",
            "label": "Snowflake user (for OAuth only)",
            "type": "STRING",
            "description": "The Snowflake user to run dbt when OAuth is used",
            "mandatory": false
        }
    ],

    /* list of required permissions on the project to see/run the runnable */
    "permissions": [],

    /* what the code's run() returns:
       - NONE : no result
       - HTML : a string that is a html (utf8 encoded)
       - FOLDER_FILE : a (folderId, path) pair to a file in a folder of this project (json-encoded)
       - FILE : raw data (as a python string) that will be stored in a temp file by DSS
       - URL : a url
     */
    "resultType": "RESULT_TABLE",

    /* label to use when the runnable's result is not inlined in the UI (ex: for urls) */
    "resultLabel": "Tables / Views generated by the dbt flow",

    /* for FILE resultType, the extension to use for the temp file */
    "extension": "txt",

    /* for FILE resultType, the type of data stored in the temp file */
    "mimeType": "text/plain",

    /* Macro roles define where this macro will appear in DSS GUI. They are used to pre-fill a macro parameter with context.

       Each role consists of:
        - type: where the macro will be shown
            * when selecting DSS object(s): DATASET, DATASETS, API_SERVICE, API_SERVICE_VERSION, BUNDLE, VISUAL_ANALYSIS, SAVED_MODEL, MANAGED_FOLDER
            * in the global project list: PROJECT_MACROS
        - targetParamsKey(s): name of the parameter(s) that will be filled with the selected object
    */
    "macroRoles": [
     /* {
            "type": "DATASET",
            "targetParamsKey": "input_dataset"
        } */
    ]
}
